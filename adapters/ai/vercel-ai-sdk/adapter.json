{
  "id": "ai/vercel-ai-sdk",
  "name": "Vercel AI SDK",
  "description": "Pure Vercel AI SDK for building AI-powered applications with streaming, chat, and text generation",
  "version": "1.0.0",
  "role": "adapter",
  "category": "ai",
  "tags": [
    "ai",
    "vercel",
    "openai",
    "streaming",
    "chat",
    "llm",
    "generation"
  ],
  "compatibility": {
    "frameworks": [
      "nextjs",
      "react",
      "svelte",
      "vue"
    ],
    "runtimes": [
      "nodejs",
      "edge",
      "browser"
    ]
  },
  "dependencies": [],
  "features": {
    "streaming": true,
    "chat": true,
    "textGeneration": true,
    "imageGeneration": true,
    "embeddings": true,
    "functionCalling": true,
    "toolUse": true,
    "reactHooks": true,
    "edgeRuntime": true,
    "caching": true
  },
  "provides": [
    "ai-core",
    "{{#if features.streaming}}ai-streaming{{/if}}",
    "{{#if features.advanced}}ai-advanced{{/if}}",
    "{{#if features.enterprise}}ai-enterprise{{/if}}"
  ],
  "parameters": {
    "providers": {
      "type": "array",
      "description": "AI providers to include",
      "default": [
        "openai",
        "anthropic"
      ],
      "enum": [
        "openai",
        "anthropic",
        "google",
        "cohere",
        "huggingface"
      ]
    },
    "features": {
      "core": {
        "type": "boolean",
        "default": true,
        "description": "Essential AI functionality (chat, text generation)"
      },
      "streaming": {
        "type": "boolean",
        "default": true,
        "description": "Real-time streaming responses"
      },
      "tools": {
        "type": "boolean",
        "default": false,
        "description": "Function calling and tool use"
      },
      "embeddings": {
        "type": "boolean",
        "default": false,
        "description": "Text embeddings functionality"
      },
      "advanced": {
        "type": "boolean",
        "default": false,
        "description": "Advanced AI features (image generation, embeddings, function calling)"
      },
      "enterprise": {
        "type": "boolean",
        "default": false,
        "description": "Enterprise features (caching, edge runtime, tool use)"
      }
    },
    "defaultModel": {
      "type": "string",
      "description": "Default AI model",
      "default": "gpt-3.5-turbo",
      "enum": [
        "gpt-3.5-turbo",
        "gpt-4",
        "gpt-4-turbo",
        "claude-3-sonnet",
        "claude-3-opus"
      ]
    },
    "maxTokens": {
      "type": "number",
      "description": "Maximum tokens for generation",
      "default": 1000
    },
    "temperature": {
      "type": "number",
      "description": "Temperature for generation",
      "default": 0.7,
      "minimum": 0,
      "maximum": 2
    }
  },
  "internal_structure": {
    "core": {
      "provides": [
        "ai-core"
      ],
      "templates": [
        "ai-config.ts",
        "ai-types.ts",
        "use-chat.ts",
        "chat-route.ts"
      ]
    },
    "streaming": {
      "prerequisites": [
        "ai-core"
      ],
      "provides": [
        "ai-streaming"
      ],
      "templates": [
        "use-streaming.ts",
        "streaming-utils.ts"
      ]
    },
    "advanced": {
      "prerequisites": [
        "ai-core"
      ],
      "provides": [
        "ai-advanced"
      ],
      "templates": [
        "image-generation.ts",
        "embeddings.ts",
        "function-calling.ts",
        "completion-route.ts"
      ]
    },
    "enterprise": {
      "prerequisites": [
        "ai-core",
        "ai-streaming"
      ],
      "provides": [
        "ai-enterprise"
      ],
      "templates": [
        "caching.ts",
        "edge-runtime.ts",
        "tool-use.ts",
        "ai-providers.ts"
      ]
    }
  },
  "blueprint": {
    "file": "blueprint.ts"
  }
}
